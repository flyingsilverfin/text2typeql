# Text2TypeQL: An Open Dataset for Teaching Models to Query TypeDB

Foundation models generate SQL and Cypher reasonably well. Large public corpora, benchmark datasets, and years of Stack Overflow answers give them plenty to learn from. TypeQL 3.0, released with TypeDB 3.0, has none of that. Very little TypeQL exists in the wild, and even frontier models like GPT-4 and Claude struggle to produce correct queries without heavy prompting or chain-of-thought scaffolding. This limits adoption in a practical way: developers cannot simply ask an LLM for help writing TypeQL the way they can with SQL. We wanted to change that.

## What We Built

**text2typeql** is an open-source dataset of natural-language questions paired with validated TypeQL 3.0 queries, drawn from two source datasets and spanning fifteen diverse domains. Over 8,100 queries have been converted so far, with conversion ongoing toward the full 14,000+ target:

- **Social networks** (Twitter, Bluesky) -- users, tweets/posts, hashtags, retweets/reposts, follows
- **Streaming platforms** (Twitch, Neoflix) -- streamers, games, teams, subscriptions, movies, ratings
- **Film industry** (Movies) -- actors, directors, producers, reviews, roles
- **Recommendations** -- users, movies, genres, ratings, actors
- **Corporate graphs** (Companies) -- organizations, subsidiaries, CEOs, articles, cities
- **Fiction networks** (Game of Thrones) -- characters, houses, battles, interactions across five books
- **Q&A platforms** (BuzzOverflow, StackOverflow) -- users, questions, answers, tags, comments, votes
- **Financial crime** (FinCEN) -- filings, entities, countries, originators, beneficiaries
- **Business reviews** (GrandStack) -- businesses, users, reviews, categories
- **Infrastructure** (Network) -- devices, interfaces, connections, configurations
- **Supply chain** (Northwind) -- products, suppliers, customers, orders, categories
- **Investigations** (OffshoreLeaks) -- officers, entities, intermediaries, addresses

The dataset is built from two source collections. **Synthetic-1** contains 4,776 queries across seven databases, of which 4,728 were successfully converted (99%). **Synthetic-2** contains 9,267 queries across fifteen databases, adding eight new domains and expanded coverage of the original seven. Conversion of Synthetic-2 is in progress: six databases are complete (Bluesky, BuzzOverflow, Companies, FinCEN, Game of Thrones, GrandStack) with 3,452 queries converted and 93 documented as unconvertible, and work continues on the remaining nine. Each successful entry includes the English question, the original Cypher query, and the validated TypeQL. The dataset ships with fifteen TypeQL schemas modelling each domain.

## Where It Comes From

The source material is Neo4j Labs' [text2cypher](https://github.com/neo4j-labs/text2cypher) benchmark, which contains two synthetically generated datasets of English/Cypher pairs across demo databases with realistic schemas. The first dataset (synthetic-1) contains approximately 4,800 pairs across seven databases, generated by Claude Opus. The second dataset (synthetic-2) contains approximately 9,300 pairs across fifteen databases, generated by GPT-4o -- adding eight entirely new domains while also providing independent coverage of the original seven. Together they were designed to evaluate and fine-tune LLMs on natural-language-to-Cypher translation. We took the same questions and schemas, converted everything to TypeQL 3.0, and preserved the original Cypher alongside each query for direct comparison. Full credit to Neo4j Labs for creating and open-sourcing the original datasets.

## How It Was Generated

The conversion pipeline had five stages, each catching a different class of error.

**Schema conversion.** Neo4j schemas were manually translated to TypeQL 3.0. Node labels became entity types, relationship types became relation types with explicit roles, and properties became attributes. TypeQL's richer type system sometimes required extending schemas beyond the Neo4j originals -- adding explicit entity subtypes, key constraints, or role distinctions to capture semantics that Cypher leaves implicit in property values or query-time conventions.

**Query conversion via AI agents.** Each Cypher query was converted to TypeQL using Claude Code subagents operating under a detailed TypeQL 3.0 reference. This was not mechanical transpilation. TypeQL's syntax and semantics differ from Cypher in fundamental ways: relations require explicit role names, query clauses follow a strict `match` then `sort` then `limit` then `fetch` ordering, aggregation uses `reduce` rather than implicit grouping, and subquery logic is expressed through custom functions. The agents reasoned about the English question's intent, not just the Cypher syntax. In several cases, the original Cypher was arguably wrong (using the wrong property or relation direction), and the TypeQL was written to correctly answer the English question instead.

**Validation against TypeDB.** Every generated query was executed against a live TypeDB 3.0 instance to verify parsing and type-checking. This step caught syntax errors, incorrect role names, missing attributes, and type mismatches that were syntactically plausible but semantically invalid against the loaded schema.

**Semantic review.** A second pass verified that each TypeQL query actually answers the English question -- not just that it is valid TypeQL. This caught wrong relation directions (e.g., "tweets retweeted by others" versus "tweets that retweet others"), missing filter conditions, incorrect aggregation targets, and cases where optional-match semantics required `try {}` blocks rather than mandatory patterns.

**Failure documentation.** Queries that genuinely cannot be expressed in TypeQL 3.0 were documented with specific reasons: string length functions (`size()`), array index access, epoch timestamp conversion, duration arithmetic, `collect()` aggregation, Neo4j spatial types (Point), and similar gaps. Across synthetic-1, 48 queries fell into this category; synthetic-2 adds a further 93 so far, with the same recurring patterns plus Neo4j Point type property access and additional `collect()` use cases. These entries provide a clear picture of TypeQL's current functional boundaries.

The dataset exercises a broad range of TypeQL 3.0 features: custom functions (`with fun`), chained reduce for HAVING-equivalent post-aggregation filtering, `let` expressions for computed values, type variables for polymorphic matching across relation types, negation, disjunction, and regex patterns via `like`.

## What the Type System Caught

Two categories of issues surfaced during conversion that were not anticipated but turned out to be valuable signals.

**Queries that cannot be expressed in TypeQL.** Across both datasets, a small percentage of source queries require language features that TypeQL 3.0 does not yet support: string length functions (`size()`), array indexing and iteration, epoch timestamp conversion, duration arithmetic, date component extraction (`weekday`, `year`), `collect()` aggregation, percentile functions, and Neo4j spatial type property access (Point `.latitude`/`.longitude`). Each is documented with its original Cypher and the specific missing capability. In synthetic-1, 48 of 4,776 queries fell into this category. Synthetic-2 adds 93 more across six completed databases, with the same recurring patterns plus Neo4j Point type access (GrandStack location queries) and additional `collect()` use cases for list aggregation. Rather than noise, these entries constitute a precise feature-gap analysis -- a checklist of what TypeQL would need to achieve full parity with Cypher's function library.

**Original Cypher queries that were incorrect.** More unexpectedly, TypeDB's strict type system exposed roughly 30 queries across four databases where the original Cypher does not correctly answer the English question. These were not TypeQL bugs -- the Cypher itself was wrong, and the looseness of Cypher's schema allowed the errors to go undetected. Three patterns recurred. First, *wrong property*: eight Twitter queries check `t.favorites` (likes) when the question asks about retweets. TypeQL has no property that conflates the two -- the `retweets` relation must be explicitly matched, forcing the correct semantics. Second, *wrong direction*: five Companies queries reverse the supplier/customer direction in the `HAS_SUPPLIER` relationship. TypeQL's `supplies (supplier: $x, customer: $y)` requires an explicit role assignment, making the reversal immediately visible. Third, *wrong traversal path*: several Twitter queries traverse `(user)-[:FOLLOWS]->(:Me)-[:POSTS]->(tweet)`, returning tweets by Me rather than tweets by followers. TypeQL's role-based relation syntax (`posts (author: $u, content: $t)`) forces the converter to specify which entity is the author, eliminating the ambiguity. In each case the TypeQL was written to correctly answer the English question rather than reproduce the Cypher's mistake.

These findings suggest that a strongly typed query language can serve as a static analysis layer over a dataset -- catching semantic errors that pass silently in more permissive systems.

## How This Helps

**Fine-tuning.** The dataset provides supervised training data for fine-tuning smaller, faster models (Llama, Mistral, Phi, and similar) on TypeQL generation. The fifteen-domain coverage ensures models encounter diverse schema patterns -- from simple entity lookups to complex multi-hop financial crime investigations. This enables local, low-latency, cost-effective text-to-TypeQL without relying on frontier model APIs.

**Few-shot prompting and RAG.** The thousands of validated examples serve as a rich retrieval corpus for retrieval-augmented generation or few-shot in-context learning. Given a user's natural-language question, a system can retrieve similar questions from the dataset and include their TypeQL as examples in the prompt. The dual-source nature (synthetic-1 and synthetic-2) also provides natural train/test splits for the seven overlapping domains.

**Evaluation benchmark.** The dataset provides a standardized measure of TypeQL generation quality, analogous to what text2cypher provides for Cypher. Researchers and engineers can evaluate model accuracy against known-good queries across varying complexity levels.

**Learning resource.** Side-by-side Cypher and TypeQL for the same English question makes the dataset a practical reference for engineers learning TypeQL. Seeing how familiar Cypher patterns map to TypeQL -- explicit roles, `reduce` for aggregation, `let` for computed values -- builds intuition faster than documentation alone.

**Feature coverage.** The fifteen domains collectively exercise nearly the full breadth of TypeQL 3.0 query syntax, from simple entity lookups to custom functions with chained aggregation stages. The expanded synthetic-2 domains add patterns underrepresented in the original seven -- financial transaction chains (FinCEN), supply chain hierarchies (Northwind), network topologies (Network), and investigation graphs (OffshoreLeaks). Models trained on this data will encounter the patterns they need for real-world use.

## Get Involved

The dataset is available on GitHub. We welcome contributions: additional domains, alternative TypeQL formulations for existing queries, or conversions of the 141 currently-failed queries as TypeQL gains new features. The pipeline and tooling are included in the repository, so extending the dataset follows the same validated workflow.
